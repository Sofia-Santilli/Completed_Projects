# Completed_Projects

## Table of contents

* [**Bachelor degree projects**](https://github.com/Sofia-Santilli/Completed_Projects/tree/main/Bachelor's%20degree%20projects)
* [**Master degree projects**](https://github.com/Sofia-Santilli/Completed_Projects/tree/main/Master's%20degree%20projects)
***

## Bachelor degree projects

***

## Master degree projects

1. **Machine Learning**

2. **Reinforcement Learning**

3. **Fundations of Computer Graphics**

4. **Interactive Graphics**

5. **Natural Language Processing**

6. **Autonomous and Mobile Robots**

7. [**Neural Networks**](https://github.com/Sofia-Santilli/Completed_Projects/tree/main/Master%20degree%20projects/Neural%20Networks): Reimplementation of the approach proposed by the paper "[_Learning strides in convolutional neural networks_](https://arxiv.org/pdf/2202.01653.pdf)".
We reimplemented two different pooling layers, used instead of the strides in the convolutional layers and that work in the frequency domain (Fixed spectral pooling and Learnable spectral pooling).
We also substituted the classical Conv2d layers in the network with [_Parametrized Hypercomplex Convolutional layers_](https://arxiv.org/pdf/2110.04176.pdf), which allow to reduce the overall number of parameters by a factor of N.

8. [**Deep Learning**](https://github.com/Sofia-Santilli/Completed_Projects/tree/main/Master%20degree%20projects/Deep%20Learning): development of architectures that address the Visual Question Answering task. It is a semantic task that aims to answer questions based on an image.
These questions require an understanding of vision, language and commonsense knowledge to answer. The VQA v2.0 dataset, containing open-ended questions about images, has been employed.

9. **Elective in AI - part1**

10. **Elective in AI - Human-Robot Interaction and Reasoning**: The project consists in making a Pepper robot, named
Hanoi, able to perform the reasoning needed to solve the Tower of Hanoi game and to do this by taking
turns with a human user. 
* The reasoning part was implemented through the AIplan4UE framework, that allowed the robot to plan the most suitable actions to performe in the game.
* Regarding the human-robot interaction part we provided different modalities to make the user interact with the robot,
specifically verbally and through its tablet. Moreover, given the importance of interpersonal distances in
social interactions, we make sure that the robot starts an interaction only when a person gets close to it. 
At the same time, the robot stays still and does not get closer itself,
otherwise it would risk invading the user’s intimate zone. 
Finally, we make the robot collect information about the user to build a simplified user’s profile that allows 
to successfully interact with people of different ages and to suggest to the person the most appropriate level of the game.


***